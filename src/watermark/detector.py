import torch
import math
from transformers import PreTrainedTokenizer
from .jamo_utils import get_last_syllable_jamo
from .hash_policy import HashPolicy

class JamoWatermarkDetector:
    """
    Detects and extracts a watermark from text generated by JamoWatermarkProcessor.
    """
    def __init__(self, tokenizer: PreTrainedTokenizer, original_message: str, mode: str = 'robustness', k_bits: int = 2):
        self.tokenizer = tokenizer
        self.mode = mode
        self.k_bits = k_bits
        #self.step_t = 0
        # The detector must know the payload to check if the extracted bits match the target.
        byte_data = original_message.encode('utf-8')
        self.payload = ''.join(format(byte, '08b') for byte in byte_data)
        self.hash_policy = HashPolicy(mode=self.mode, k_bits=self.k_bits)

    def _extract_bits_from_token(self, token_str: str) -> int | None:
        """
        Extracts the embedded bits from a single token based on the current step.
        """
        # 1. Decompose the last syllable of the token into Jamo indices
        jamo_indices = get_last_syllable_jamo(token_str)
        
        # If the token has no Hangul syllable, it couldn't have been watermarked.
        if jamo_indices is None:
            return None

        # 2. Select the channel (Choseong, Jungseong, Jongseong) based on the current step
        # This must follow the same round-robin logic as the processor.
        channel_idx = self.step_t % 3

        # 3. Calculate the hashes for all three channels
        token_hashes = self.hash_policy.calculate_channel_hashes(*jamo_indices)

        # 4. The extracted bits are the hash value of the selected channel
        extracted_bits = token_hashes[channel_idx]
        
        return extracted_bits

    def extract_payload(self, input_ids: torch.LongTensor, target_payload: str) -> tuple[float, str]:
        """
        Extracts the full watermark payload from a sequence of token IDs.
        """
        extracted_payload = ""

        self.step_t = 0 # Reset step counter for each new text
        detected_cnt = 0
        total_steps = 0

        # Decode the entire sequence once, then split into tokens (re-tokenization; note_251107)
        token_ids = input_ids[0].tolist()

        for token_id in token_ids:

            if self.step_t * self.k_bits >= len(target_payload):
                break

            # Skip special tokens like BOS/EOS
            if token_id in self.tokenizer.all_special_ids:
                continue
            
            # Use convert_ids_to_tokens to get the raw token string,
            # which prevents re-tokenization issues (e.g., ' 인' -> '인').
            # This ensures consistency with the generation process.
            token_str = self.tokenizer.convert_ids_to_tokens(token_id)
            extracted_bits = self._extract_bits_from_token(token_str)

            # This is the core synchronization logic for the detector.
            if extracted_bits is not None: # If the token contains a Hangul syllable
                # Get the target bits that should have been embedded at this step
                target_bits = int(self.payload[self.step_t * self.k_bits : (self.step_t + 1) * self.k_bits], 2)

                # Check if the extracted bits match the target bits
                if extracted_bits == target_bits:
                    # This token was successfully watermarked. Append the bits and advance the step.
                    binary_representation = format(extracted_bits, f'0{self.k_bits}b')
                    extracted_payload += binary_representation
                    self.step_t += 1
                    detected_cnt += 1
                else:
                    # If it does not match, step_t remains the same,
                    # and we will check the next token against the same target_bits.
                    total_steps += 1
                    pass
        total_steps = len(target_payload) // self.k_bits
        
        if total_steps > 0:
            accuracy = detected_cnt / total_steps
            
            # Z-Score Calculation
            p0 = 1.0 / (2 ** self.k_bits)
            n = total_steps
            expected_matches = n * p0
            std_dev = math.sqrt(n * p0 * (1 - p0))
            
            if std_dev > 0:
                z_score = (detected_cnt - expected_matches) / std_dev
            else:
                z_score = 0.0
        else:
            accuracy = 0.0
            z_score = 0.0
        
        return accuracy, extracted_payload, z_score