# 251123

## 진행 현황

1. 주요 문제점: 동기화 오류<br>
- 기존에는 transformers 라이브러리로부터 LogitsProcessor 클래스를 직접 import 하였다. 따라서 샘플링 단계 이전에 step_t를 업데이트 하면서, 샘플링 이후 실제 생성된 토큰과 워터마크가 어긋날 가능성이 있었다.
- 해결: 직접 기존 클래스를 가져오는 것이 아니라, 수동으로 loop를 구현했다. LogitProcessor 상속을 processor.py에서 제거했고, logits 편향 및 토큰 일치 여부를 확인해주는 헬퍼 클래스를 만들었다. 이로써 sampling 이후에 step_t를 결정할 수 있도록 하였다. 즉, < logits 계산 -> 편향 적용 -> 샘플링 (토큰 선택) -> 결과 확인 후 step_t 결정 > 과 같은 순서로 토큰 선택 및 워터마킹이 진행된다.

2. 탐지 전략 재확인
- 탐지기가 워터마크를 탐지하는 방식은 non-blind 방식으로 결정했다. 즉 워터마크 문자열을 아는 상태임을 가정하는 것이다. 탐지기가 워터마크를 모른다고 가정해서 blind extraction을 시도해 보았지만, ECC(Reed solomon) 및 패딩을 적용해도 오류율이 너무 높아서 워터마크를 복원할 수 없었다. 
- 대신 원래 구현한 방식대로, 텍스트를 생성할 때 워터마크 삽입에 실패하면 step을 건너뛰기 하고 다음 토큰에서 재시도 하도록 한다. 워터마크로 삼은 문자열 알고 있으므로, 탐지 시에는 생성된 텍스트를 순차적으로 읽으면서 정답과 일치하는 토큰이 나올 때만 step을 진행하여 동기화할 수 있다.
- 향후 고칠 점: 현재는 생성기에서 토큰이 생성되면 저장해 두었다가 탐지기에서 그대로 사용해서 검증하고 있는데, 이 둘을 독립적으로 분리해야 할 것 같다. 이를 위해서는, 일반적인 텍스트를 다시 토큰화했을 때 해당 텍스트가 LLM에서 생성될 때와 정확히 같은 토큰 단위로 분리할 수 있을지 확인해야 할 것이다. (참고할 것: transformers 라이브러리의 decode 함수 등)

3. 현재 파라미터 값
bias: 5.0
top-k: 30개
생성 토큰: 200개
(verification에 이상 없음)

