### 한글의 자음과 모음 구조에 기반한 3-Channel LLM 워터마킹<br>(3-Channel LLM Watermarking for Hangul Jamo Structure)<br>
**강희지**

### 연구 배경 및 필요성 
대규모 언어 모델(LLM)이 생성한 텍스트가 급증하면서, 가짜 뉴스 또는 저작권 분쟁 등 다양한 문제가 발생하고 있다. 이러한 문제들을 해결하고자 등장한 것이 LLM 워터마킹이다. 이것은 특정 텍스트가 AI의 생성물인지 식별하는 기술로, 대표적으로 LLM에서 어떤 토큰을 선택할지 그 확률을 조정하는 방식이 있다(Kirchenbauer). 이때 텍스트에 삽입된 워터마크는 사람이 읽었을 때 확인할 수 없다. 이렇게 워터마크가 삽입된 생성물은 적합한 탐지기를 통해 나온 확률값을 보고 그것이 LLM이 생성한 것인지 확인할 수 있게 된다.  <br><br>
그러나 현재 발표되고 있는 워터마킹 기술들의 접근 방식에는 근본적인 한계가 있다. 첫번째로, 주류 워터마킹 기술 및 이에 사용되는 토크나이저들이 영어를 기반으로 한다(*출처 필요). 기존의 Kirchenbauer 또는 Google의 SynthID와 같은 워터마킹 방법은 주로 영어 데이터셋 기준으로 설계되었다(*출처 필요). 근본적으로 모델에서 사용되는 토크나이저 또한 영어를 기반으로 한다. 예를 들어 BPE(Byte-Pair Encoding)은 subword 단위로 텍스트를 분리한다. 그러나 이러한 접근은 한국어와 같은 교착어(agglutinative language)에 적합하지 않다. 교착어란 어간에 조사나 어미가 붙는 복잡한 형태를 띠는 언어를 의미하는데, 대표적으로 한국어를 들 수 있다. 이러한 언어를 서브워드로 분리하는 경우 조사나 어미에 담긴 의미를 해치면서, 워터마크 삽입 시 불규칙적인 단위로 토큰을 조합할 가능성이 있다(*섹션2). 두번째로 현재 워터마킹 기술은 한글의 구조적 특성을 충분히 활용하지 못하고 있다. 한글은 세 가지 음소 초성, 중성, 종성이 모여 하나의 음절을 이루는 독창적인 구조를 가진 언어이다. 그러나 기존의 방식은 온전한 토큰 즉 음절 혹은 단어 형태의 토큰 ID를 이용하기 때문에, 음절 내부에 존재하는 음소 단위 구조를 십분 활용하지 못한다.  <br><br>
여기서 본 프로젝트는 한글의 음운론적 특성인 자음과 모음 구조를 활용하여 새로운 워터마킹 프레임워크를 제안하고자 한다. 음절보다 더 작은 구조인 음소 단위를 활용하면, 워터마크로 삽입할 수 있는 정보의 양을 증대할 수 있을 것이라는 가설에서 출발한다.<br>
### 관련 연구 및 문제 정의 
섹션1에서 토크나이저의 문제점을 확인하기 위해 간단한 실험을 진행하였다. <br>그림1 - 영어 서브워드 분리 (어느정도 의미를 보존; 예-동사+시제로 분리) <br> 그림2 - 한글 서브워드 분리 (안 + 녕하세요; 불규칙한 토큰 단위) <br><br>
이를 바탕으로, 기존 워터마킹 접근법의 문제점을 정의하고자 한다. 첫번째로, kirchenbauer가 제안한 방식을 살펴보았다. 이 방식은 어휘(vocabulary)를 green/red list로 분할하여, 토큰을 생성할 때 green list의 토큰을 선택하도록 확률적 편향을 부여하여 유도한다. 토크나이저에 정의된 토큰 단위에 따라 버킷을 나누기 때문에 이 방식은 토큰ID에 의존하게 된다. 여기서 문제는, 이렇게 사전에 정의된 토큰 단위에 의존하면서 영어와 상이한 구조의 한국어는 문맥적 또는 형태적 유사성이 무시된 채 토큰을 인식한다. 예를 들어, ‘경복궁을’, ‘경복궁에’ 처럼 명사가 같아도 조사에 따라 다른 토큰으로 인식된다. 이것은 조사의 의미를 고려하여 다른 토큰으로 인식되는 것이 아니고, 단지 ‘을’과 ‘에’라는 조사의 유사성을 인식하지 못했기 때문일 뿐이다. 이러한 방식으로는 언어의 구조적 특성을 무시하고 품질 저하(perplexity)를 유발한다. 두번째로 Google DeepMind의 SynthID는 비트패턴을 워터마크로 삽입하는 방식을 채택하고 있다(*출처 필요). 이 때 토큰의 logit값을 미세하게 조정하여 비트 패턴을 숨긴다. 그러나 이 역시 토큰 단위의 확률 분포를 조작하는 것이다. 따라서 한국어처럼 하나의 음절을 여러 음소가 조합된 문자는 그 내부 구조를 충분히 활용하지 못한다.  <br><br>
따라서, 본 프로젝트는 토큰 ID 자체를 해싱하는 것이 아닌, 토큰을 구성하는 음소 단위인 자음과 모음(초성, 중성, 종성)을 분해한다. 그리고 이 3개의 음소 단위를 각각 독립적인 정보 채널로 활용하고자 한다. 이러한 접근 방식을 통해 워터마크 정보 저장량을 증대하며 기존 방식의 한계를 극복하고자 한다.<br>
### 제안 방법 (3-Channel Jamo Watermarking) 
본 프로젝트의 핵심은 토크나이저의 logit processor 단계를 조작하는 것이다. 해당 단계에서 후보 토큰을 자모 단위로 분해하고, 이를 3개의 채널 - 초, 중, 종성 으로 나누어 워터마크를 삽입한다. <br><br>
3-1. 핵심 메커니즘: 자모 분해 및 비트 부여 자음과 모음 단위로 음절을 분리하기 위해서 유니코드 산술 분해를 행한다(unicode arithmetic decomposition; * 출처필요). 한글의 각 음절은 해당하는 유니코드 값을 가지고 있다. 이것을 각 초성, 중성, 종성의 가짓수에 따라서 나누기 함으로써 초, 중, 종 인덱스를 얻을 수 있다. 여기서 인덱스라 함은 철자의 순서를 의미한다. 또한, 한 토큰의 모든 음절을 분리하지 않는다. 모든 top-k 토큰의 모든 음절을 분리하면 처리과정에 너무 많은 시간이 걸릴 것으로 판단했다. 따라서 마지막 음절만을 분해하는 방식을 택하였다. 다음으로, 이렇게 분리된 각 음소는 인덱스는 해시 함수를 거쳐 비트 값으로 변환된다. 해시 함수는 동적으로 그 방식을 변경할 수 있도록 hash policy 코드를 독립적으로 구현했고, 해당 프로젝트에서는 간단한 모듈로 연산을 택했다. 이 과정을 거치면 총 3개의 비트 값을 얻게 되는데, 한 단계에 사용할 비트 값은 하나이다. 즉 지금 토큰 t를 선택하려는 과정인 step_t에서, 초중종 3개의 채널 중 하나를 택해 워터마크와 비트가 일치하는지 검사한다. 3개의 채널은 현재 round robin 방식으로 순차적으로 선택하도록 구현해두었다. <br><br>
3-2. generation phase (생성 과정)  워터마크를 삽입하는 방식은 우리가 보편적으로 생각하는 것과 같이 직관적인 방법을 택했는데, 문자열을 비트 패턴으로 심는 것이다. 예를 들어 “LLM”이라는 문자열을 ‘워터마크’라고 정의하고, 이것을 모델이 생성하는 텍스트에 몰래 심고자 한다. 그러면 “LLM”의 각 캐릭터를 바이트 값으로 변환하고, 각 캐릭터당 8개 비트 총 24개의 비트로 이루어진 패턴이 우리가 심고자 하는 워터마크가 되는 것이다. 그 다음으로, 이 워터마크를 한글 텍스트에 심는 방법을 소개하자면 다음과 같다. <br><br>
(1) logits 단계 개입: 모델이 다음 토큰을 예측할 때, top-k개의 후보 토큰을 자음과 모음 단위로 분리한다. 다만 각 토큰의 모든 분리 가능한 음절을 분리하는 것이 아니고, 마지막 음절만 분리한다. 이유는 지나친 연산량으로 인한 오버헤드를 방지하기 위해서이다.  음소 단위 분리는 앞서 언급했듯이 유니코드 산술 분해로 이루어진다. 유니코드에서 한글 코드값은 0xAC00(“가”)부터 시작한다. 초성은 19개, 중성은 21개, 종성은 28개이다. 이들의 조합으로 코드가 배열되어 있는데, “가”의 인덱스를 0으로 삼으면, 한 음절의 인덱스는 다음과 같다(*출처필요). (초성*21*28) + (중성*28) +종성  따라서 각 음소의 인덱스를 구하기 위해서는 단순히 이 식을 역산하면 얻을 수 있다.  <br><br>
(2) 타겟 비트 매칭: 삽입하기로 정한 워터마크의 비트 패턴에서 현재 단계에 해당하는 t번째 비트와, 해당 단계에서 골라야 하는 자모 채널의 해시 값의 일치 여부를 판단한다. 여기서 해당 단계의 자모 채널이란 초,중,종 세가지 채널을 의미하고, 각 t단계마다 돌아가면서 채널을 선택한다. 예를 들어 라운드로빈 방식에 의해서 현재 중성 채널의 순서라고 가정하자. 따라서 top-k 각 후보 토큰의 마지막 음절을 분리하고 나온 초,중,종성 값 중 중성을 택한다. 그리고 중성 인덱스를 갖고 해시 함수를 계산한다. 함수를 거친 결과값을 워터마크 비트와 비교한다. 여기서 해시 함수 식에는 큰 의미를 두지 않았으며, 추후에 변경할 수 있도록 해시 policy를 독립적으로 떼어놓았다.  <br><br>
(3) 편향 부여: 이전 단계에서, 타겟비트와 토큰 음소의 해시 값이 일치하면 편향을 준다. 편향을 주는 것의 의미는 해당 토큰의 logit 값에 편향을 주어 선택될 확률을 높인다는 의미이다. <br> <br>
(4) 동기화: 워터마크 비트패턴의 인덱스인 step_t는, 토큰을 선택할 때만 증가하도록 동기화 방식을 취했다. 즉 비트가 매칭되지 않으면 step_t는 증가하지 않고 해당 단계를 스킵한다. 여기서 단계를 스킵함은 모든 top-k에 대해서 아무 토큰도 일치하지 않아 넘어간다는 것을 의미한다. <br><br>
3-3. detection phase (탐지 과정) 워터마크의 탐지는 non blind 방식으로 이루어진다. 즉 kirchenbauer의 논문에서와 같이 워터마크를 이미 탐지기가 안다고 가정하고 행한다(*출처필요). 탐지 과정은 다음과 같다. <br><br>
(1) 재토큰화: 탐지할 텍스트를 입력받는다. 해당 텍스트를 transformers 라이브러리 함수를 사용해 재토큰화한다.  <br><br>
(2) 순차적으로 검증: 생성과 정확히 같은 방식으로 토큰의 마지막 음절의 자모 단위를 분리해 해시값을 확인한다. 이렇게 텍스트의 각 토큰에 대해서 검사 후 페이로드를 완성시킨다. 여기서 주의할 점은, 텍스트가 어떤 모델에서 생성된 것이라면 그 모델의 토크나이저와 같은 것으로 재토큰화해야 한다. 그래야 특정 토크나이저의 어휘사전에 정의된 대로 정확히 같은 단위의 토큰 배열을 찾아낼 수 있기 때문이다. <br><br>
(3) 메세지 복원: 이렇게 얻은 페이로드를 8개 비트씩 나누어 바이트 값으로 계산하고, 해당 바이트 값과 일치하는 문자를 찾아서 메세지를 복원한다.<br>
### 실험 및 결과 
이 설계 방법이 실제로 유효한지 검증하기 위해서 일련의 실험을 진행하였다. 실험에는 한국어에 최적화된 경량 모델인 kogpt2-base-v2 모델을 사용하였다. <br><br>
4-1. 메세지 삽입 및 복원 성능 (capacity, accuracy) 삽입할 워터마크는 편의상 아스키 변환이 손쉬운 영어로 구성했다. 임의로 프롬프트를 하드코딩하고, 그 다음  문자열부터 모델이 생성하도록 하였다. 메세지의 복원 정도는 워터마킹 편향값 및 생성하는 토큰의 수에 크게 좌우되었다. 편향값이 높을수록 메세지는 정해진 수의 토큰을 생성할 동안 충분히 워터마크를 삽입했고, 이에 따라 복원도 100퍼센트의 정확도로 이루어졌다. 그러나 편향값이 낮을수록 워터마크 비트와 매칭되지 않는 토큰이 선택되는 횟수가 늘면서, 정해진 생성 횟수 안에 워터마크를 전부 삽입하지 못했다. 여러 번의 실험 결과 편향값은 5.0, 생성 토큰 수는 200으로 설정하였다. (*복원 성공율 추가) 해당 실험은 본 프로젝트의 자음 모음 분해 로직이 정확히 동작하였음을 증명한다. <br><br>
4-2. 강건성 다음으로 생성된 문장에서 단어를 임의로 삭제하는 공격을 시뮬레이션하였다. 텍스트에서 단어 하나만을 골라 삭제하도록 하였는데, 이유는 한 단어만으로도 비트로 변환하면 상당한 범위를 차지하기 때문이다. 이렇게 일부 단어를 삭제하여 문맥을 훼손한 후, 워터마크 메세지가 얼마나 복원되는지를 퍼센티지로 정의했다. 결과적으로, 단어를 삭제한 후에도 남은 토큰들 속에 분산되어 저장된 자모 비트 패턴을 통해서 메세지의 핵심적인 부분을 성공적으로 복구할 수 있었다. (*결과 수치 필요) 여기서 50%이상의 비율로 워터마크를 복원하면 성공한 것으로 간주했다. 이 실험은 음소 단위의 미세한 패턴이 텍스트 전반에 걸쳐서 견고히 삽입됨을 의미한다.<br>
### 결론 
본 프로젝트는 LLM에서 한국어를 타겟으로 하여 한글 특화적인 음소 기반 3채널 워터마킹 기술을 구현했다. 해당 프로젝트는 다음과 같은 시사점을 갖는다고 생각한다. 첫번째로 독창성이다. 지금까지 등장한 대부분의 워터마킹 기술은 토큰 ID를 단위 기준으로 삼았다. 그러나 본 프로젝트에서는 자모 즉 음소라는 한국어 언어의 독특한 구조를 워터마킹 단위로 삼아, 언어적인 특성이 시스템 설계에 반영되도록 하였다. 두번째로 구현을 통한 증명이다. transformers 라이브러리의 logitsprocessor를 커스텀하여 토큰이 생성되는 실시간 파이프라인에 성공적으로 개입하는 아키텍쳐를 구현하였다. 마지막으로 언어 특화적 접근이라는 의의를 들 수 있겠다. AI 기술은 영미권 위주로 흐르고 있으나, 이러한 비영어권 언어의 특성을 활용해 워터마킹의 성능과 품질 유지를 증명하여 새로운 대안을 제시하였다. 향후에 한국어 생성형 AI의 투명성을 확보할 신뢰성 있는 솔루션이라고 기대한다.
